{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled57.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMc0NUQXJ6ayP2Wu9WVTyEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/tf00/blob/master/6%20-%20Generatori%20e%20Images%20Augmentation/generators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9SoXhZyrPB",
        "colab_type": "text"
      },
      "source": [
        "# Generatori di Immagini\n",
        "Spesso capita di dover addestrare una rete neurale su una mole di dati talmente grande da non riuscire a risiedere sulla memoria del nostro PC. A questo scopo tf.keras ci mette a disposizione i generatori, uno strumento che permette di caricare le immagini in batch durante la fase di addestramento.<br>\n",
        "In questo notebook vedremo come utilizzare i generatori per addestrare una rete neurale in grado di distinguere 5 diversi tipi di dessert, utilizzando un dataset di 10.000 immagini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lIzsEL9zQyM",
        "colab_type": "text"
      },
      "source": [
        "## Scarichiamo il Dataset\n",
        "Il dataset che utilizzeremo è un'estratto del Food101, una raccolta di 101.000 immagini appartenenti a 101 categorie di cibi. Nel nostr caso le categorie sono solamente le seguenti: \n",
        " - cannoli\n",
        " - gelato\n",
        " - panna cotta\n",
        " - tiramisu\n",
        " - torta di mele\n",
        "\n",
        "All'interno dell'archivio troviamo sia la cartella con 10.000 immagini per l'addestramento, 2000 per classe, e la cartella con 1250 immagini per il test, 250 per classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyOa3RQSmv4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f0ef14df-2cee-446a-9a14-76aafafd5071"
      },
      "source": [
        "!wget https://profession.ai/datasets/dessert.zip\n",
        "!unzip -qq dessert.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-29 11:01:23--  https://profession.ai/datasets/dessert.zip\n",
            "Resolving profession.ai (profession.ai)... 13.225.25.129, 13.225.25.127, 13.225.25.27, ...\n",
            "Connecting to profession.ai (profession.ai)|13.225.25.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261265207 (249M) [application/zip]\n",
            "Saving to: ‘dessert.zip’\n",
            "\n",
            "dessert.zip         100%[===================>] 249.16M  95.4MB/s    in 2.6s    \n",
            "\n",
            "2020-06-29 11:01:26 (95.4 MB/s) - ‘dessert.zip’ saved [261265207/261265207]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0txxTk30QyR",
        "colab_type": "text"
      },
      "source": [
        "## Importiamo i Moduli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWRBp74AnLRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0MYZgud0S7S",
        "colab_type": "text"
      },
      "source": [
        "## Definiamo le Costanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVyUUWKnU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_DIR = \"dessert/\"\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TOT_IMAGES = 10000 \n",
        "IMG_SIZE = (228, 228)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KcFCnNh0ZJo",
        "colab_type": "text"
      },
      "source": [
        "## Creiamo il Generatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngy6n2S40d6P",
        "colab_type": "text"
      },
      "source": [
        "Possiamo creare il generatore utilizzando la classe *ImageDataGenerator* di tf.keras, al suo interno possiamo definire la dimensione del set di validazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoCKyAzZ0auH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_train = ImageDataGenerator(validation_split=0.1, rescale=1./255,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e7j_sUf1yXs",
        "colab_type": "text"
      },
      "source": [
        "tramite il parametro *rescale* abbiamo definito come normalizzare le immagini, cioè dividendo per 255.<br>\n",
        "Ora per creare i generatori di immagini, utilizziamo il metodo *flow_from_directory*, specificando:\n",
        " - il path al set di immagini\n",
        " - *target_size*: la dimensione da utilizzare per le immagini\n",
        " - *batch_size*: la dimensione di ogni batch di immagini\n",
        " - *class_mode*: la tipologia di classificazione, multiclasse (categorical) o binaria (binary).\n",
        " - *subset*: qui possiamo specificare se si tratta del set di training o di validazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpr62Dk2naf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "383eb861-7014-4fa9-a7ca-68dbce1396b2"
      },
      "source": [
        "train_generator = datagen_train.flow_from_directory(\n",
        "        DATASET_DIR+\"train\", \n",
        "        target_size=IMG_SIZE, \n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "valid_generator = datagen_train.flow_from_directory(\n",
        "        DATASET_DIR+\"train\",\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')\n",
        "\n",
        "print(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 5 classes.\n",
            "Found 1000 images belonging to 5 classes.\n",
            "Found 1250 images belonging to 5 classes.\n",
            "{'cannoli': 0, 'gelato': 1, 'panna_cotta': 2, 'tiramisu': 3, 'torta_di_mele': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKCmrA7d2zxF",
        "colab_type": "text"
      },
      "source": [
        "Ora creiamo anche un generatore per il Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CembZOAR1_ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_test = ImageDataGenerator(rescale=1./255,)\n",
        "\n",
        "test_generator = datagen_test.flow_from_directory(\n",
        "        DATASET_DIR+\"test\",\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n",
        "print(test_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh9RkxW33Amn",
        "colab_type": "text"
      },
      "source": [
        "## Addestriamo la Rete Neurale Convoluzionale sul Generatore\n",
        "Definiamo l'architettura della rete, trattandosi di un problema abbastanza complesso utilizzeremo diversi strati, insieme a dropout e regolarizzazione L2 per cercare di limitare l'overfiting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aln-iSetnd2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "e99ddfc7-dd09-4b03-8469-acb596b78b02"
      },
      "source": [
        "#regularizer = tf.keras.regularizers.L1L2(l1=0.01, l2=0.1)\n",
        "regularizer = tf.keras.regularizers.L1L2(l2=0.1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=3))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=3))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 228, 228, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 228, 228, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 76, 76, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 76, 76, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 76, 76, 32)        18464     \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 76, 76, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 256)               5120256   \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 5,228,165\n",
            "Trainable params: 5,228,165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxoYyWbl3M-E",
        "colab_type": "text"
      },
      "source": [
        "Per avviare l'addestramento ci basterà passare al metodo *fit* il generatore di addestramento e l'eventuale generatore di validazione. Dobbiamo solo stare attenti a specificare il numero di steps per ogni epoca del Gradient Descent, perché quando utilizziamo i generatori Tensorflow non è in grado di ottenere questo valore automaticamente, solitamente basta utilizzare: NUMERO_DI_IMMAGINI_NEL_SET/DIMENSIONE_DEL_BATCH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3rQYmkrngo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a349b1ef-fbe9-4b7b-e66b-04bfaf3edc0c"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                              min_delta=0.01,\n",
        "                              patience=3,\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(TOT_IMAGES*0.9 // BATCH_SIZE),\n",
        "        validation_data=valid_generator, \n",
        "        validation_steps=int(TOT_IMAGES*0.1 // BATCH_SIZE),\n",
        "        epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "140/140 [==============================] - 83s 596ms/step - loss: 2.6104 - accuracy: 0.1970 - val_loss: 1.6121 - val_accuracy: 0.1969\n",
            "Epoch 2/100\n",
            " 47/140 [=========>....................] - ETA: 51s - loss: 1.6107 - accuracy: 0.1955"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br7SMNPl32Ga",
        "colab_type": "text"
      },
      "source": [
        "# Testiamo la Rete sul Generatore\n",
        "Per testare sul generatore la Rete Neurale che abbiamo addestrato, ci basta passare il generatore al metodo *evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1mM8_-Oni7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "35fed362-e1b8-4272-c207-4094638f76a2"
      },
      "source": [
        "metrics_train = model.evaluate(train_generator)\n",
        "metrics_test = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Train Accuracy = %.4f - Train Loss = %.4f\" % (metrics_train[1], metrics_train[0]))\n",
        "print(\"Test Accuracy = %.4f - Test Loss = %.4f\" % (metrics_test[1], metrics_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 90/141 [==================>...........] - ETA: 12s - loss: 1.6128 - accuracy: 0.1924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e3f9e74d9e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetrics_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Accuracy = %.4f - Train Loss = %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetrics_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy = %.4f - Test Loss = %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetrics_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}