{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled57.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJooXZGcAmWxoIqDqmWjH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/tf00/blob/master/6%20-%20Generatori%20e%20Images%20Augmentation/generators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9SoXhZyrPB",
        "colab_type": "text"
      },
      "source": [
        "# Generatori di Immagini\n",
        "Spesso capita di dover addestrare una rete neurale su una mole di dati talmente grande da non riuscire a risiedere sulla memoria del nostro PC. A questo scopo tf.keras ci mette a disposizione i generatori, uno strumento che permette di caricare le immagini in batch durante la fase di addestramento.<br>\n",
        "In questo notebook vedremo come migliorare il nostro modello per riconoscere casi di malaria, sfruttando un generatore per eseguire l'addestramento su tutte le immagini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lIzsEL9zQyM",
        "colab_type": "text"
      },
      "source": [
        "## Scarichiamo il Dataset\n",
        "Questa volta, piuttosto che usare tensorflow datasets, scarichiamo la raccolta di immagini direttamente dal sito ufficiale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyOa3RQSmv4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3a60b588-f921-4930-88b9-b12165ee02a1"
      },
      "source": [
        "!wget ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
        "!unzip -qq cell_images.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-03 14:31:49--  ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
            "           => ‘cell_images.zip’\n",
            "Resolving lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)... 130.14.55.35, 2607:f220:41e:7055::35\n",
            "Connecting to lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)|130.14.55.35|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /Open-Access-Datasets/Malaria ... done.\n",
            "==> SIZE cell_images.zip ... 353452851\n",
            "==> PASV ... done.    ==> RETR cell_images.zip ... done.\n",
            "Length: 353452851 (337M) (unauthoritative)\n",
            "\n",
            "cell_images.zip     100%[===================>] 337.08M  3.22MB/s    in 36s     \n",
            "\n",
            "2020-07-03 14:32:29 (9.27 MB/s) - ‘cell_images.zip’ saved [353452851]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX1_5l31GAjN",
        "colab_type": "text"
      },
      "source": [
        "Le immagini sono raccolte dentro due sotto-cartelle:\n",
        "* **Parasitized**: contiene le immagini di cellule di pazienti infetti.\n",
        "* **Uninfected**: contiene le immagini di cellule di pazienti sani."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0txxTk30QyR",
        "colab_type": "text"
      },
      "source": [
        "## Importiamo i Moduli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWRBp74AnLRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0MYZgud0S7S",
        "colab_type": "text"
      },
      "source": [
        "## Definiamo le Costanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVyUUWKnU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_DIR = \"cell_images/\"\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TOT_IMAGES = 27558 \n",
        "IMG_SIZE = (228, 228)\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KcFCnNh0ZJo",
        "colab_type": "text"
      },
      "source": [
        "## Creiamo il Generatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngy6n2S40d6P",
        "colab_type": "text"
      },
      "source": [
        "Possiamo creare il generatore utilizzando la classe *ImageDataGenerator* di tf.keras, al suo interno possiamo definire la dimensione del set di validazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoCKyAzZ0auH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_train = ImageDataGenerator(validation_split=VALIDATION_SPLIT rescale=1./255,)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e7j_sUf1yXs",
        "colab_type": "text"
      },
      "source": [
        "tramite il parametro *rescale* abbiamo definito come normalizzare le immagini, cioè dividendo per 255.<br>\n",
        "Ora per creare i generatori di immagini, utilizziamo il metodo *flow_from_directory*, specificando:\n",
        " - il path al set di immagini\n",
        " - *target_size*: la dimensione da utilizzare per le immagini\n",
        " - *batch_size*: la dimensione di ogni batch di immagini\n",
        " - *class_mode*: la tipologia di classificazione, multiclasse (categorical) o binaria (binary).\n",
        " - *subset*: qui possiamo specificare se si tratta del set di training o di validazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpr62Dk2naf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "17f5a4f4-6e0b-4f7d-ad0b-11555147063b"
      },
      "source": [
        "train_generator = datagen_train.flow_from_directory(\n",
        "        DATASET_DIR,\n",
        "        target_size=IMG_SIZE, \n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "valid_generator = datagen_train.flow_from_directory(\n",
        "        DATASET_DIR,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "print(train_generator.class_indices)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24804 images belonging to 2 classes.\n",
            "Found 2754 images belonging to 2 classes.\n",
            "{'Parasitized': 0, 'Uninfected': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh9RkxW33Amn",
        "colab_type": "text"
      },
      "source": [
        "## Addestriamo la Rete Neurale Convoluzionale sul Generatore\n",
        "Definiamo l'architettura della rete, trattandosi di un problema abbastanza complesso utilizzeremo diversi strati, insieme a dropout e regolarizzazione L2 per cercare di limitare l'overfiting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aln-iSetnd2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "01dd7810-7cdd-4540-e8e9-88acda00308a"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=3))\n",
        "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=3))\n",
        "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 228, 228, 32)      416       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 76, 76, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 76, 76, 32)        4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 25, 25, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8, 8, 128)         8320      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,380,289\n",
            "Trainable params: 4,380,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxoYyWbl3M-E",
        "colab_type": "text"
      },
      "source": [
        "Per avviare l'addestramento ci basterà passare al metodo *fit* il generatore di addestramento e l'eventuale generatore di validazione. Dobbiamo solo stare attenti a specificare il numero di steps per ogni epoca del Gradient Descent, perché quando utilizziamo i generatori Tensorflow non è in grado di ottenere questo valore automaticamente, solitamente basta utilizzare: NUMERO_DI_IMMAGINI_NEL_SET/DIMENSIONE_DEL_BATCH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3rQYmkrngo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "98a6f53e-3a56-479e-eda5-5123f02b938d"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                              min_delta=0.01,\n",
        "                              patience=3,\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(TOT_IMAGES*(1.-VALIDATION_SPLIT) // BATCH_SIZE),\n",
        "        validation_data=valid_generator, \n",
        "        validation_steps=int(TOT_IMAGES*VALIDATION_SPLIT // BATCH_SIZE),\n",
        "        epochs=5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "387/387 [==============================] - 58s 149ms/step - loss: 0.3684 - accuracy: 0.8241 - val_loss: 0.2291 - val_accuracy: 0.9182\n",
            "Epoch 2/5\n",
            "387/387 [==============================] - 57s 148ms/step - loss: 0.1595 - accuracy: 0.9531 - val_loss: 0.1967 - val_accuracy: 0.9266\n",
            "Epoch 3/5\n",
            "387/387 [==============================] - 57s 147ms/step - loss: 0.1412 - accuracy: 0.9583 - val_loss: 0.2155 - val_accuracy: 0.9288\n",
            "Epoch 4/5\n",
            "387/387 [==============================] - 57s 147ms/step - loss: 0.1342 - accuracy: 0.9594 - val_loss: 0.2069 - val_accuracy: 0.9306\n",
            "Epoch 5/5\n",
            "387/387 [==============================] - 57s 148ms/step - loss: 0.1255 - accuracy: 0.9612 - val_loss: 0.1972 - val_accuracy: 0.9339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4549534a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br7SMNPl32Ga",
        "colab_type": "text"
      },
      "source": [
        "# Testiamo la Rete sul Generatore\n",
        "Per testare sul generatore la Rete Neurale che abbiamo addestrato, ci basta passare il generatore al metodo *evaluate*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1mM8_-Oni7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "884fe892-2475-4499-b5c8-45ae9a924855"
      },
      "source": [
        "metrics_train = model.evaluate(train_generator)\n",
        "metrics_valid = model.evaluate(valid_generator)\n",
        "\n",
        "print(\"Train Accuracy = %.4f - Train Loss = %.4f\" % (metrics_train[1], metrics_train[0]))\n",
        "print(\"Validation Accuracy = %.4f - Validation Loss = %.4f\" % (metrics_valid[1], metrics_valid[0]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "388/388 [==============================] - 46s 119ms/step - loss: 0.1067 - accuracy: 0.9645\n",
            "44/44 [==============================] - 5s 116ms/step - loss: 0.1971 - accuracy: 0.9339\n",
            "Train Accuracy = 0.9645 - Train Loss = 0.1067\n",
            "Validation Accuracy = 0.9339 - Validation Loss = 0.1971\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}