{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled74.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq1LZlsI76XVRDdhdCLBBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/tf00/blob/master/9%20-%20Word%20Embedding/trained_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnhPU1Tbt0K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Flatten, Dropout"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVCI_BiC00yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_WORDS = 10000\n",
        "NUM_EMBEDDING = 50\n",
        "SEQ_MAX_LENGTH = 50"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UwnwnKt7FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def load_imdb(files_path, labels=[\"pos\", \"neg\"]):\n",
        "    \n",
        "    if(not os.path.isfile(\"aclImdb_v1.tar.gz\")):\n",
        "      os.system(\"wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\")\n",
        "      os.system(\"tar -xf aclImdb_v1.tar.gz\")\n",
        "    \n",
        "    label_map = {labels[0]:1, labels[1]:0}\n",
        "    \n",
        "    reviews = []\n",
        "    y = []\n",
        "    \n",
        "    for label in labels:\n",
        "      path = files_path+label\n",
        "      for file in os.listdir(path):\n",
        "        review_file = open(path+\"/\"+file)\n",
        "        review = review_file.read()    \n",
        "        \n",
        "        reviews.append(review)\n",
        "        y.append(label_map[label])\n",
        "        \n",
        "    # la funzione shuffle di sklearn ci permette di\n",
        "    # mescolare pi√π array allo stesso modo\n",
        "    \n",
        "    reviews, y = shuffle(reviews,y)\n",
        "    \n",
        "    return(reviews,y)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPxOgQQuEz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5b0b67ed-db12-44ea-f75d-d9269527b1e9"
      },
      "source": [
        "reviews_train, y_train = load_imdb(\"aclImdb/train/\")\n",
        "reviews_test, y_test = load_imdb(\"aclImdb/test/\")\n",
        "\n",
        "print(\"Prima recensione del set di test\")\n",
        "print(reviews_test[0])\n",
        "print(\"Sentiment: %d\" % y_test[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prima recensione del set di test\n",
            "This film as it is now is far shorter than it was when released in 1918. In fact, it is now more available with two other medium sized silent Chaplin features (A DOG'S LIFE, and THE PILGRIM) that Chaplin re-released in the 1950s. In it's day SHOULDER ARMS was a big hit because of it's humor in uniform approach. It still is very funny (Chaplin in disguise as a tree, spying on the Germans, is so ridiculous it's hysterical), but it suffers from being set in it's own age. Charlie's dealing with World War I, a hideous conflict that killed 20 million people, but not the worst war (horrible to say) of the 20th Century. Chaplin would live to see that war too, and would spoof it's main architects in THE GREAT DICTATOR. But the latter is more accessible to modern audiences because that movie is a talking picture. Also, Hitler as a target seems more important to audiences in 2008 than Kaiser Wilhelm II and his general staff.<br /><br />SHOULDER ARMS was to take us through the drafting of the tramp, his training, his getting use to trench warfare, and his actual fighting against the \"Huns\" on the Western Front. Much of this is now gone - one segment (when Albert Austin is a Doctor examining Chaplin in his office at the draft center) is still in existence and was shown completely in the documentary UNKNOWN CHAPLIN. This is unfortunate, because the film is now roughly forty five minutes long, and there seems to be gaps that these scenes filled out. What remains is first rate but one leaves wanting more...and feeling a trifle cheated.<br /><br />Sydney Chaplin and Henry Bergman do well in supporting parts, especially Sydney as Wilhelm. He had done it before in a short with Charlie for the sale of bonds, giving a militaristic speech before being clobbered by the tramp with a huge hammer labeled \"War Bonds\"). Here we see the tramp succeed in capturing Wilhelm and the general staff at the conclusion. It was only topped by Stan and Ollie capturing the German army with a tank and barbed wire in PACK UP YOUR TROUBLES.<br /><br />The funny thing is that Chaplin actually had a major crisis as a result of his wartime activities. He was not a naturalized American - not in 1917 or in 1952, when Attorney General McGranery publicly announced that Chaplin could not return to the U.S. because he was an enemy alien (Chaplin and his family were in Europe on a trip - in anger Charlie settled in Switzerland for the rest of his life, except when he made A COUNTESS FROM HONG KONG and when he went to Hollywood for his special career \"Oscar\" in the 1970s). Because he was not an American he could not be drafted by the U.S. So he sold (with Douglas Fairbanks Sr. and Mary Pickford) U. S. War Bonds. But in Great Britain tens of thousands had perished in World War One battlefields, and the public there was upset at Chaplin, who they considered a \"slacker\" and a coward. Chaplin eventually did overcome this, but remnants of the resentment followed him until he died. This does not detract from the success of SHOULDER ARMS as a film, but it does suggest why Chaplin did not do another modern war film until 1940, and a worthier target.\n",
            "Sentiment: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZhE82aluVze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e0566d9-783a-4ebd-952f-bee7c17cb1b4"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenizer.fit_on_texts(reviews_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "X_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "\n",
        "X_test[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11,\n",
              " 19,\n",
              " 14,\n",
              " 9,\n",
              " 6,\n",
              " 147,\n",
              " 6,\n",
              " 227,\n",
              " 5850,\n",
              " 71,\n",
              " 9,\n",
              " 13,\n",
              " 51,\n",
              " 622,\n",
              " 8,\n",
              " 8,\n",
              " 189,\n",
              " 9,\n",
              " 6,\n",
              " 147,\n",
              " 50,\n",
              " 1434,\n",
              " 16,\n",
              " 104,\n",
              " 82,\n",
              " 3461,\n",
              " 6388,\n",
              " 1290,\n",
              " 3499,\n",
              " 941,\n",
              " 3,\n",
              " 110,\n",
              " 2,\n",
              " 1,\n",
              " 12,\n",
              " 3499,\n",
              " 792,\n",
              " 622,\n",
              " 8,\n",
              " 1,\n",
              " 3064,\n",
              " 8,\n",
              " 42,\n",
              " 248,\n",
              " 5400,\n",
              " 2795,\n",
              " 13,\n",
              " 3,\n",
              " 191,\n",
              " 566,\n",
              " 85,\n",
              " 4,\n",
              " 42,\n",
              " 483,\n",
              " 8,\n",
              " 6352,\n",
              " 1480,\n",
              " 9,\n",
              " 128,\n",
              " 6,\n",
              " 52,\n",
              " 160,\n",
              " 3499,\n",
              " 8,\n",
              " 5628,\n",
              " 14,\n",
              " 3,\n",
              " 2841,\n",
              " 20,\n",
              " 1,\n",
              " 4606,\n",
              " 6,\n",
              " 35,\n",
              " 645,\n",
              " 42,\n",
              " 3772,\n",
              " 18,\n",
              " 9,\n",
              " 2476,\n",
              " 36,\n",
              " 109,\n",
              " 267,\n",
              " 8,\n",
              " 42,\n",
              " 202,\n",
              " 555,\n",
              " 7307,\n",
              " 1950,\n",
              " 16,\n",
              " 179,\n",
              " 322,\n",
              " 10,\n",
              " 3,\n",
              " 4238,\n",
              " 1942,\n",
              " 12,\n",
              " 554,\n",
              " 888,\n",
              " 1428,\n",
              " 81,\n",
              " 18,\n",
              " 21,\n",
              " 1,\n",
              " 246,\n",
              " 322,\n",
              " 524,\n",
              " 5,\n",
              " 132,\n",
              " 4,\n",
              " 1,\n",
              " 3648,\n",
              " 1115,\n",
              " 3499,\n",
              " 59,\n",
              " 409,\n",
              " 5,\n",
              " 64,\n",
              " 12,\n",
              " 322,\n",
              " 96,\n",
              " 2,\n",
              " 59,\n",
              " 2833,\n",
              " 42,\n",
              " 290,\n",
              " 8,\n",
              " 1,\n",
              " 84,\n",
              " 8461,\n",
              " 18,\n",
              " 1,\n",
              " 1563,\n",
              " 6,\n",
              " 50,\n",
              " 6338,\n",
              " 5,\n",
              " 679,\n",
              " 1218,\n",
              " 85,\n",
              " 12,\n",
              " 17,\n",
              " 6,\n",
              " 3,\n",
              " 660,\n",
              " 428,\n",
              " 79,\n",
              " 2143,\n",
              " 14,\n",
              " 3,\n",
              " 2391,\n",
              " 183,\n",
              " 50,\n",
              " 671,\n",
              " 5,\n",
              " 1218,\n",
              " 8,\n",
              " 5047,\n",
              " 71,\n",
              " 1532,\n",
              " 2,\n",
              " 24,\n",
              " 828,\n",
              " 3992,\n",
              " 7,\n",
              " 7,\n",
              " 5400,\n",
              " 2795,\n",
              " 13,\n",
              " 5,\n",
              " 190,\n",
              " 175,\n",
              " 140,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 8332,\n",
              " 24,\n",
              " 2330,\n",
              " 24,\n",
              " 394,\n",
              " 358,\n",
              " 5,\n",
              " 2,\n",
              " 24,\n",
              " 776,\n",
              " 994,\n",
              " 426,\n",
              " 1,\n",
              " 20,\n",
              " 1,\n",
              " 1008,\n",
              " 1007,\n",
              " 73,\n",
              " 4,\n",
              " 11,\n",
              " 6,\n",
              " 147,\n",
              " 821,\n",
              " 28,\n",
              " 2049,\n",
              " 51,\n",
              " 2055,\n",
              " 5180,\n",
              " 6,\n",
              " 3,\n",
              " 1038,\n",
              " 3499,\n",
              " 8,\n",
              " 24,\n",
              " 1048,\n",
              " 30,\n",
              " 1,\n",
              " 9546,\n",
              " 2212,\n",
              " 6,\n",
              " 128,\n",
              " 8,\n",
              " 2007,\n",
              " 2,\n",
              " 13,\n",
              " 616,\n",
              " 337,\n",
              " 8,\n",
              " 1,\n",
              " 661,\n",
              " 1860,\n",
              " 3499,\n",
              " 11,\n",
              " 6,\n",
              " 2409,\n",
              " 85,\n",
              " 1,\n",
              " 19,\n",
              " 6,\n",
              " 147,\n",
              " 7159,\n",
              " 4203,\n",
              " 674,\n",
              " 231,\n",
              " 193,\n",
              " 2,\n",
              " 47,\n",
              " 183,\n",
              " 5,\n",
              " 27,\n",
              " 7329,\n",
              " 12,\n",
              " 131,\n",
              " 136,\n",
              " 1058,\n",
              " 43,\n",
              " 48,\n",
              " 1285,\n",
              " 6,\n",
              " 83,\n",
              " 966,\n",
              " 18,\n",
              " 28,\n",
              " 886,\n",
              " 1780,\n",
              " 50,\n",
              " 2,\n",
              " 544,\n",
              " 3,\n",
              " 4580,\n",
              " 7,\n",
              " 7,\n",
              " 6543,\n",
              " 3499,\n",
              " 2,\n",
              " 1461,\n",
              " 5004,\n",
              " 78,\n",
              " 70,\n",
              " 8,\n",
              " 694,\n",
              " 528,\n",
              " 259,\n",
              " 6543,\n",
              " 14,\n",
              " 26,\n",
              " 66,\n",
              " 221,\n",
              " 9,\n",
              " 156,\n",
              " 8,\n",
              " 3,\n",
              " 343,\n",
              " 16,\n",
              " 1438,\n",
              " 15,\n",
              " 1,\n",
              " 6413,\n",
              " 4,\n",
              " 9075,\n",
              " 740,\n",
              " 3,\n",
              " 2491,\n",
              " 156,\n",
              " 109,\n",
              " 31,\n",
              " 1,\n",
              " 8332,\n",
              " 16,\n",
              " 3,\n",
              " 663,\n",
              " 4222,\n",
              " 8381,\n",
              " 322,\n",
              " 9075,\n",
              " 130,\n",
              " 72,\n",
              " 64,\n",
              " 1,\n",
              " 8332,\n",
              " 3123,\n",
              " 8,\n",
              " 4753,\n",
              " 2,\n",
              " 1,\n",
              " 828,\n",
              " 3992,\n",
              " 30,\n",
              " 1,\n",
              " 1172,\n",
              " 9,\n",
              " 13,\n",
              " 61,\n",
              " 9826,\n",
              " 31,\n",
              " 3347,\n",
              " 2,\n",
              " 5221,\n",
              " 4753,\n",
              " 1,\n",
              " 1122,\n",
              " 1268,\n",
              " 16,\n",
              " 3,\n",
              " 5199,\n",
              " 2,\n",
              " 5854,\n",
              " 8,\n",
              " 3152,\n",
              " 53,\n",
              " 126,\n",
              " 4931,\n",
              " 7,\n",
              " 7,\n",
              " 1,\n",
              " 160,\n",
              " 152,\n",
              " 6,\n",
              " 12,\n",
              " 3499,\n",
              " 162,\n",
              " 66,\n",
              " 3,\n",
              " 675,\n",
              " 3128,\n",
              " 14,\n",
              " 3,\n",
              " 957,\n",
              " 4,\n",
              " 24,\n",
              " 7633,\n",
              " 4950,\n",
              " 26,\n",
              " 13,\n",
              " 21,\n",
              " 3,\n",
              " 296,\n",
              " 21,\n",
              " 8,\n",
              " 39,\n",
              " 8,\n",
              " 51,\n",
              " 4838,\n",
              " 828,\n",
              " 7511,\n",
              " 12,\n",
              " 3499,\n",
              " 97,\n",
              " 21,\n",
              " 992,\n",
              " 5,\n",
              " 1,\n",
              " 1204,\n",
              " 587,\n",
              " 85,\n",
              " 26,\n",
              " 13,\n",
              " 32,\n",
              " 2546,\n",
              " 1526,\n",
              " 3499,\n",
              " 2,\n",
              " 24,\n",
              " 220,\n",
              " 68,\n",
              " 8,\n",
              " 2376,\n",
              " 20,\n",
              " 3,\n",
              " 1185,\n",
              " 8,\n",
              " 2556,\n",
              " 1438,\n",
              " 6823,\n",
              " 8,\n",
              " 9468,\n",
              " 15,\n",
              " 1,\n",
              " 357,\n",
              " 4,\n",
              " 24,\n",
              " 110,\n",
              " 546,\n",
              " 51,\n",
              " 26,\n",
              " 90,\n",
              " 3,\n",
              " 36,\n",
              " 2585,\n",
              " 1987,\n",
              " 2,\n",
              " 51,\n",
              " 26,\n",
              " 432,\n",
              " 5,\n",
              " 360,\n",
              " 15,\n",
              " 24,\n",
              " 315,\n",
              " 608,\n",
              " 732,\n",
              " 8,\n",
              " 1,\n",
              " 3469,\n",
              " 85,\n",
              " 26,\n",
              " 13,\n",
              " 21,\n",
              " 32,\n",
              " 296,\n",
              " 26,\n",
              " 97,\n",
              " 21,\n",
              " 27,\n",
              " 31,\n",
              " 1,\n",
              " 1204,\n",
              " 587,\n",
              " 35,\n",
              " 26,\n",
              " 2956,\n",
              " 16,\n",
              " 1766,\n",
              " 6728,\n",
              " 9482,\n",
              " 2,\n",
              " 1084,\n",
              " 6381,\n",
              " 1204,\n",
              " 587,\n",
              " 322,\n",
              " 9075,\n",
              " 18,\n",
              " 8,\n",
              " 84,\n",
              " 3510,\n",
              " 4,\n",
              " 3073,\n",
              " 66,\n",
              " 8,\n",
              " 179,\n",
              " 322,\n",
              " 28,\n",
              " 2,\n",
              " 1,\n",
              " 1068,\n",
              " 47,\n",
              " 13,\n",
              " 3052,\n",
              " 30,\n",
              " 3499,\n",
              " 34,\n",
              " 33,\n",
              " 1189,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 8206,\n",
              " 3499,\n",
              " 850,\n",
              " 119,\n",
              " 3080,\n",
              " 11,\n",
              " 18,\n",
              " 4,\n",
              " 1,\n",
              " 1475,\n",
              " 87,\n",
              " 363,\n",
              " 26,\n",
              " 1127,\n",
              " 11,\n",
              " 124,\n",
              " 21,\n",
              " 6204,\n",
              " 36,\n",
              " 1,\n",
              " 1020,\n",
              " 4,\n",
              " 5400,\n",
              " 2795,\n",
              " 14,\n",
              " 3,\n",
              " 19,\n",
              " 18,\n",
              " 9,\n",
              " 124,\n",
              " 1462,\n",
              " 135,\n",
              " 3499,\n",
              " 119,\n",
              " 21,\n",
              " 78,\n",
              " 157,\n",
              " 679,\n",
              " 322,\n",
              " 19,\n",
              " 363,\n",
              " 5891,\n",
              " 2,\n",
              " 3,\n",
              " 2391]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwsAclSTxoYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "27ce0715-b18b-463e-e31f-1f51ffb0ebc7"
      },
      "source": [
        "longest_review = max(X_train,key=len)\n",
        "shortest_review = min(X_train,key=len)\n",
        "\n",
        "print(\"La review pi√π lunga ha %d parole\" % len(longest_review))\n",
        "print(\"La review pi√π corta ha %d parole\" % len(shortest_review))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La review pi√π lunga ha 2193 parole\n",
            "La review pi√π corta ha 9 parole\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEeWyQHCx5Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f78acb56-3593-4336-e7e4-0b629fdf3c6d"
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen = SEQ_MAX_LENGTH)\n",
        "X_test = pad_sequences(X_test, maxlen = SEQ_MAX_LENGTH)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H83eJmz90OdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WiNTMOPx73D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "3b6d3d35-adb0-4c64-cb1d-e20693f3f894"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(MAX_WORDS, NUM_EMBEDDING, input_length=SEQ_MAX_LENGTH))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 50, 50)            500000    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2500)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               320128    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 824,289\n",
            "Trainable params: 824,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh3okaPVyv4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "87c9a552-dfe9-40ec-e20d-02b2b9fab1be"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=10)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 1.2148 - accuracy: 0.5031 - val_loss: 0.7317 - val_accuracy: 0.5092\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.7748 - accuracy: 0.5347 - val_loss: 0.6925 - val_accuracy: 0.5258\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.7427 - accuracy: 0.5738 - val_loss: 0.6463 - val_accuracy: 0.5904\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.6647 - accuracy: 0.6305 - val_loss: 0.6144 - val_accuracy: 0.6262\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.6075 - accuracy: 0.6912 - val_loss: 0.5255 - val_accuracy: 0.7380\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5432 - accuracy: 0.7466 - val_loss: 0.4914 - val_accuracy: 0.7442\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4896 - accuracy: 0.7973 - val_loss: 0.4562 - val_accuracy: 0.8040\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4506 - accuracy: 0.8367 - val_loss: 0.4599 - val_accuracy: 0.7982\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.8576 - val_loss: 0.5118 - val_accuracy: 0.8016\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.3475 - accuracy: 0.8794 - val_loss: 0.5821 - val_accuracy: 0.8106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f764502fb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpeM-U8-2o8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c37c4de6-54df-499b-c2e6-f555905e1a68"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6025 - accuracy: 0.8012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6025338768959045, 0.8011599779129028]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_f4-c92ncN",
        "colab_type": "text"
      },
      "source": [
        "## Testiamo la Rete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX2l2E2R0FlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fc47c25e-55ac-4eb9-ecfb-4f839277bdf3"
      },
      "source": [
        "reviews = [\"This movie sucks, I just wasted two hours of my life\", \"Best movie I have ever seen, the ending was so touching and I made me crying so much.\", \"Not a bad movie\"]\n",
        "\n",
        "reviews = tokenizer.texts_to_sequences(reviews)\n",
        "X = pad_sequences(reviews, maxlen = SEQ_MAX_LENGTH)\n",
        "\n",
        "y = model.predict(X)\n",
        "print(y)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1286717 ]\n",
            " [0.62813914]\n",
            " [0.20023899]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}