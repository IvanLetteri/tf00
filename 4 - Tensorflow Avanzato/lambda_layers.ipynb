{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwvpfHOO6AAtIvSf57jGiS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/tf00/blob/master/4%20-%20Tensorflow%20Avanzato/lambda_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9twyV00mRkS",
        "colab_type": "text"
      },
      "source": [
        "# Strati Lambda\n",
        "In questo notebook addestreremo una rete neurale per affrontare un semplicissimo problema di computer vision: riconoscere cifre scritte a mano. Inoltre vedremo come utilizzare degli **Strati Lambda** per eseguire del codice custom all'interno della rete neurale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3UYKGVzMihH",
        "colab_type": "text"
      },
      "source": [
        "## Importiamo i Moduli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SpjeUHFl_e5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7_P3lcMmUG",
        "colab_type": "text"
      },
      "source": [
        "## Prepariamo i Dati\n",
        "Il dataset che utilizzeremo è il MNIST, una raccolta di immagini in bianco e nero di cifre scritte a mano. Per importare il dataset possiamo sfruttare il modulo *tensorflow_datasets*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR4X7M2hng_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tfds.load('mnist', split='train', shuffle_files=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOKYxu9AM7zI",
        "colab_type": "text"
      },
      "source": [
        "Definiamo una funzione che legge gli esempi dal dataset e li inserisce all'interno di due array numpy, uno con le features e un'altro con i target. Utilizziamo il parametro opzionale *num_samples* per limitare il numero di esempi da utilizzare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCKbkUDLn8ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset, num_samples=None):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for i, example in enumerate(tfds.as_numpy(dataset)):\n",
        "\n",
        "    if(num_samples!=None and i>=num_samples):\n",
        "      break\n",
        "\n",
        "    images.append(example[\"image\"])\n",
        "    labels.append(example[\"label\"])\n",
        "\n",
        "  images = np.array(images)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzBDy11bNN9T",
        "colab_type": "text"
      },
      "source": [
        "Adesso utilizziamo la funzione per creare il dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJtZfgSNn_OP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2e4cfb38-9afc-4d6b-a6c9-8d20e9b89ac8"
      },
      "source": [
        "images, labels = load_data(dataset)\n",
        "num_classes = np.unique(labels).shape[0] # contiamo il numero di classi uniche\n",
        "print(\"Numero di esempi: %d\" % images.shape[0])\n",
        "print(\"Dimensioni immagine: %s\" % str(images[0].shape))\n",
        "print(\"Classi = %d %s\" % (num_classes, np.unique(labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero di esempi: 60000\n",
            "Dimensioni immagine: (28, 28, 1)\n",
            "Classi = 10 [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUy7oV53NgmE",
        "colab_type": "text"
      },
      "source": [
        "Nel caso di classificazioni multiclasse, dobbiamo codificare il target utilizzando il **one-hot encoding**, con tnsorflow possiamo farlo tramite la funzione *one_hot*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5vEv1dZn_lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = images\n",
        "y = tf.one_hot(labels, num_classes).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM8NKwpXNy7J",
        "colab_type": "text"
      },
      "source": [
        "Adesso dividiamo il dataset in Train Set e Test Set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xOqjENRoFMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8MZUqfxu-z7",
        "colab_type": "text"
      },
      "source": [
        "### Flattening delle Immagini\n",
        "L'input della nostra rete neurale deve essere sempre un vettore, mentre un'immagine è una matrice di pixel, per convertire una matrice in un vettore possiamo eseguire il **Flattening**, che consiste nel riorganizzare le varie righe del dataset in un unica riga in successione. Possiamo farlo utilizzando il metodo reshape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WziV_ZhNqt23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e840836-1a7d-432a-87ab-d48400db1fcd"
      },
      "source": [
        "X_train_1d = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test_1d = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "\n",
        "X_train_1d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc_03OjgOdrf",
        "colab_type": "text"
      },
      "source": [
        "Per assicurarci di non aver *rotto* le immagini, eseguiamo la trasformarzione inversa e proviamo a stampare un'immagine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRj56pLJoGdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f3db06dc-1e1c-496d-8696-660ebd9ba78f"
      },
      "source": [
        "plt.imshow(X_train_1d[0].reshape(28,28))\n",
        "print(np.argmax(y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMR1R3X1ppg6",
        "colab_type": "text"
      },
      "source": [
        "## Addestramento della Rete Neurale\n",
        "Definiamo e addestriamo la rete neurale, trattandosi di un problema di classificazione multiclasse, la funzione di attivazione dell'ultimo strato deve essere la sigmoide, mentre la funzione di costo da utilizzare è la Categorical Crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhufjrX_oIOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "9b7be56c-eb03-4046-b2f3-9f2bbb322d02"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=[X_train_1d.shape[1]]))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_1d, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 45.1150 - accuracy: 0.1136\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3010 - accuracy: 0.1139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb50125780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFdGG11WO_79",
        "colab_type": "text"
      },
      "source": [
        "Il risultato dell'addestramento è davvero molto scarso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOuOKfVvoo6k",
        "colab_type": "text"
      },
      "source": [
        "### Normalizzazione delle immagini\n",
        "Una rete neurale apprende molti pesi tutti di dimensione abbastanza piccola, e utilizzre delle features con valori elevati può rallentare, se non addirittura rompere, la fase di addestramento. Per questo motivo è sempre consigliabile normalizzare o standardizzare il dataset. Per normalizzare delle immagini è sufficiente dividere per 255 (il valore massimo che un pixel può avere) in modo tale da portare il range di valori a 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84KCeodppYzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_norm = X_train_1d/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ps9xjNGQvd8",
        "colab_type": "text"
      },
      "source": [
        "Proviamo ora ad addestrare nuovamente la stessa rete neurale di prima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4zb2hkLof-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "7d69aaaa-0e2e-4f3e-d981-98186bce9629"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=[X_train_norm.shape[1]]))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8145 - accuracy: 0.7680\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3442 - accuracy: 0.9006\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2868 - accuracy: 0.9162\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2550 - accuracy: 0.9255\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2317 - accuracy: 0.9322\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2135 - accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1979 - accuracy: 0.9426\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1845 - accuracy: 0.9465\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1734 - accuracy: 0.9496\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb0a3e35c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZGZ4FmjQy4b",
        "colab_type": "text"
      },
      "source": [
        "Come vedi ora il risultato è totalmente differente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVqtq5mJp6_Z",
        "colab_type": "text"
      },
      "source": [
        "## Utilizzare Strati Lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9FYpK9nQ2q0",
        "colab_type": "text"
      },
      "source": [
        "Vediamo ora come possiamo utilizzare gli strati lambda per incorporare alcuni calcoli all'interno degli stessi strati della rete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRx49wt2r7qO",
        "colab_type": "text"
      },
      "source": [
        "### Normalizzazione\n",
        "Aggiungiamo uno strato lambda prima dello strato di input, il cui scopo è normalizzare le immagini, dopodichè eseguiamo l'addestramento sul Train Set non normalizzato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIe0385Gp2mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "769af4fc-4692-475d-b4dd-133ff65992e5"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Lambda(lambda x: x/255))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=[X_train_1d.shape[1]]))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_1d, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7986 - accuracy: 0.7780\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3497 - accuracy: 0.8996\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.9138\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2681 - accuracy: 0.9227\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2444 - accuracy: 0.9299\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2253 - accuracy: 0.9346\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2088 - accuracy: 0.9397\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1944 - accuracy: 0.9441\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1816 - accuracy: 0.9477\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1703 - accuracy: 0.9510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb0a32db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iwcbCXdRNyX",
        "colab_type": "text"
      },
      "source": [
        "Come vedi il risultato è lo stesso di prima, dato che anche in questo caso la normalizzazione viene eseguita, ma avviene all'interno della rete neurale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxodJcsbr-9r",
        "colab_type": "text"
      },
      "source": [
        "### Flattening\n",
        "Aggiungiamo un'ulteriore strato Lambda, per eseguire il flattening delle immagini e addestriamo la rete sul Train Set originale, cioè quello in cui ogni immagine è rappresentata da una matrice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS09ViXvqB8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "1e3efeb3-3624-405a-f3d9-05bd38cddf79"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Lambda(lambda x: tf.reshape(x, [x.shape[0], x.shape[1]*x.shape[2]])))\n",
        "model.add(tf.keras.layers.Lambda(lambda x: x/255))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8627 - accuracy: 0.7545\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3488 - accuracy: 0.8991\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2944 - accuracy: 0.9137\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2623 - accuracy: 0.9237\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2371 - accuracy: 0.9308\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2174 - accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2012 - accuracy: 0.9420\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1877 - accuracy: 0.9450\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1762 - accuracy: 0.9486\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1672 - accuracy: 0.9512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb0a26d240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-YoPN-ZRny_",
        "colab_type": "text"
      },
      "source": [
        "Il risultato è semrpre lo stesso, abbiamo trasformato la nostra rete neurale in un modello end-to-end. Per finire valutiamo il nostro modello sul Test Set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6diMCZk8s3n2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc4cebf8-963e-4f31-d768-95373af7d026"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18978886306285858, 0.9460833072662354]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW4yNf1vR5kI",
        "colab_type": "text"
      },
      "source": [
        "Non c'è overfitting, quindi il modello va bene, quindi possiamo pure utilizzare la rete per riconoscere nuove immagini (non avendo altre immagini utilizzerò sempre il Test Set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTNsNiLqsTC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0c9a483d-7ef6-41c2-fc03-f0fa756bff6b"
      },
      "source": [
        "model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-bc459dba29cd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-bc459dba29cd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 9, ..., 2, 5, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}